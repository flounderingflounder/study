{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cab9940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from random import randint\n",
    "import numpy as np\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17356354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_num_param(net):\n",
    "    nb_param = 0\n",
    "    for param in net.parameters():\n",
    "        nb_param += param.numel()\n",
    "    print('There are {} ({:.2f} million) parameters in this neural network'.format(\n",
    "        nb_param, nb_param/1e6)\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4073ff16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 79510 (0.08 million) parameters in this neural network\n"
     ]
    }
   ],
   "source": [
    "class one_layer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(one_layer, self).__init__()\n",
    "        self.W1 = torch.nn.Linear(784, 100)\n",
    "        self.W2 = torch.nn.Linear(100, 10)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.W1(x)\n",
    "        z = torch.relu(z)\n",
    "        s = self.W2(z)        \n",
    "        return s\n",
    "\n",
    "n1 = one_layer()\n",
    "display_num_param(n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "881334ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7860, 0.8020], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class test(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(test, self).__init__()\n",
    "        self.W1 = torch.nn.Linear(2, 3)\n",
    "        self.W2 = torch.nn.Linear(3, 2)\n",
    "        \n",
    "        # Initialize the weight matrices\n",
    "        self.W1.weight.data.fill_(1.0)\n",
    "        self.W2.weight.data.fill_(1.0)\n",
    "        \n",
    "        # Initialize the biases\n",
    "        self.W1.bias.data.fill_(0.5)\n",
    "        self.W2.bias.data.fill_(0.5)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.W1(x)\n",
    "        s = self.W2(z)        \n",
    "        return s\n",
    "\n",
    "n2 = test()\n",
    "    \n",
    "    #index is flipped first index is H second index is W\n",
    "    \n",
    "with torch.no_grad():\n",
    "    n2.W1.weight[0,0]=0.1  #w1h1\n",
    "    n2.W1.weight[0,1]=0.2  #w2h1\n",
    "    \n",
    "    n2.W1.weight[1,0]=0.1  #w1h2\n",
    "    n2.W1.weight[1,1]=0.2  #w2h2\n",
    "    \n",
    "    n2.W1.weight[2,0]=0.2  #w1h3\n",
    "    n2.W1.weight[2,1]=0.3  #w2h3\n",
    "    \n",
    "    n2.W2.weight[0,0]=0.4  #h1o1\n",
    "    n2.W2.weight[0,1]=0.5  #h2o1\n",
    "    n2.W2.weight[0,2]=0.6  #h3o1\n",
    "    \n",
    "    n2.W2.weight[1,0]=0.4  #h1o2\n",
    "    n2.W2.weight[1,1]=0.5  #h2o2\n",
    "    n2.W2.weight[1,2]=0.7  #h3o2\n",
    "    \n",
    "    n2.W1.bias.data.fill_(0.03)\n",
    "    n2.W2.bias.data.fill_(0.6)\n",
    "    \n",
    "inputw = torch.Tensor([0.5,0.1])\n",
    "\n",
    "scores = n2(inputw)\n",
    "\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e3eccc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1., -1.],\n",
      "        [ 3.,  1.,  0.],\n",
      "        [-3., -1., -3.]])\n",
      "tensor(1.3862)\n"
     ]
    }
   ],
   "source": [
    "X = torch.Tensor([\n",
    "    [2,1,1],\n",
    "    [-1,0,-1],\n",
    "    [1,0,0]\n",
    "])\n",
    "\n",
    "W = torch.Tensor([\n",
    "    [1,2,0],\n",
    "    [1,1,2],\n",
    "    [-1,2,1]\n",
    "])\n",
    "Y = torch.tensor([1,2,0])\n",
    "\n",
    "output = W.mm(X) # need to transpose back because Wx \n",
    "print(output)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "cel = loss(output.T,Y)\n",
    "print(cel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "13241d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  2., 10.,  3.])\n",
      "tensor(10.0014)\n"
     ]
    }
   ],
   "source": [
    "lse = torch.Tensor([1,2,10,3])\n",
    "X = torch.Tensor([1,1,1,1])\n",
    "s = lse.mul(X)\n",
    "print(s)\n",
    "output = torch.logsumexp(s, dim=0)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309d7e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f73c9a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters :  760\n",
      "W x H x D = 32.0 x 32.0 x 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#CNN INPUT to Output\n",
    "\n",
    "inputshape = [32,32,3] #input shape \n",
    "numberfilters = 10 # depth or number of channels\n",
    "spatial_extent = 5 # 5x5 or 3x3 or 7x7 also known as F\n",
    "pad  = 2\n",
    "stride = 1\n",
    "\n",
    "W = (inputshape[0] - spatial_extent + 2*pad  )/ stride + 1\n",
    "H = (inputshape[1] - spatial_extent + 2*pad  )/ stride + 1\n",
    "D = numberfilters\n",
    "\n",
    "totalparams =  ( spatial_extent*spatial_extent*inputshape[2] +1 ) * numberfilters\n",
    "\n",
    "print(\"Total parameters : \" , totalparams)\n",
    "print(\"W x H x D = {} x {} x {}\".format(W,H,D))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcaf38a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W x H x D = 7.0 x 7.0 x 3\n"
     ]
    }
   ],
   "source": [
    "# Pooling input to output\n",
    "\n",
    "inputshape = [14,14,3]\n",
    "spatial_extent = 2 # 2x2 or size of region\n",
    "stride = 2 # usually same as spatial extent\n",
    "\n",
    "W = ((inputshape[0]-spatial_extent)/stride) + 1\n",
    "H = ((inputshape[1]-spatial_extent)/stride) + 1\n",
    "D = inputshape[2]\n",
    "\n",
    "print(\"W x H x D = {} x {} x {}\".format(W,H,D))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b48832c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 21-10-16--20-18-33\n",
      "MLP(\n",
      "  (W1): Linear(in_features=5, out_features=10, bias=True)\n",
      "  (W2): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (W3): Linear(in_features=20, out_features=2, bias=True)\n",
      ")\n",
      "tensor([[586.9000, 586.9000],\n",
      "        [696.3400, 696.3400],\n",
      "        [679.6401, 679.6401]], grad_fn=<AddmmBackward>)\n",
      "Gradient of L w.r.t for W1 is: tensor([[-28.5370,  -5.8898,   2.1796, -15.0228, -19.6454],\n",
      "        [-28.5370,  -5.8898,   2.1796, -15.0228, -19.6454],\n",
      "        [-28.5370,  -5.8898,   2.1796, -15.0228, -19.6454],\n",
      "        [-28.5370,  -5.8898,   2.1796, -15.0228, -19.6454],\n",
      "        [-28.5370,  -5.8898,   2.1796, -15.0228, -19.6454],\n",
      "        [-28.5370,  -5.8898,   2.1796, -15.0228, -19.6454],\n",
      "        [-28.5370,  -5.8898,   2.1796, -15.0228, -19.6454],\n",
      "        [-28.5370,  -5.8898,   2.1796, -15.0228, -19.6454],\n",
      "        [-28.5370,  -5.8898,   2.1796, -15.0228, -19.6454],\n",
      "        [-28.5370,  -5.8898,   2.1796, -15.0228, -19.6454]])\n",
      "Gradient of L w.r.t for b1 is: tensor([-30., -30., -30., -30., -30., -30., -30., -30., -30., -30.])\n",
      "There are 322 (0.00 million) parameters in this neural network\n"
     ]
    }
   ],
   "source": [
    "#%reset -f\n",
    "import torch\n",
    "import datetime\n",
    "print('Timestamp:',datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\"))\n",
    "\n",
    "x = torch.tensor([[ 1.0459,  0.1869,  0.1149,  0.5970,  0.4373],\n",
    "                  [ 1.0104,  0.3820,  1.0039,  0.6381, -0.1052],\n",
    "                  [-0.5516,  1.3038,  1.7466, -0.6411,  0.9880]])\n",
    "\n",
    "\n",
    "## YOUR CODE STARTS HERE \n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.W1 = torch.nn.Linear(5, 10)\n",
    "        self.W2 = torch.nn.Linear(10, 20)\n",
    "        self.W3 = torch.nn.Linear(20, 2)\n",
    "        \n",
    "        # Initialize the weight matrices\n",
    "        self.W1.weight.data.fill_(1.0)\n",
    "        self.W2.weight.data.fill_(1.0)\n",
    "        self.W3.weight.data.fill_(1.0)\n",
    "        \n",
    "        # Initialize the biases\n",
    "        self.W1.bias.data.fill_(0.5)\n",
    "        self.W2.bias.data.fill_(0.5)\n",
    "        self.W3.bias.data.fill_(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.W1(x)\n",
    "        z = torch.relu(z)\n",
    "        z = self.W2(z)\n",
    "        z = torch.relu(z)\n",
    "        s = self.W3(z)\n",
    "        return s\n",
    "       \n",
    "net = MLP()\n",
    "print(net)\n",
    "\n",
    "s = net(x)\n",
    "print(s)\n",
    "\n",
    "grad_L_s = torch.Tensor([[-3.2, 1.3], \n",
    "                         [1.2, -0.7], \n",
    "                         [-0.2, 0.1]])\n",
    "\n",
    "s.backward(gradient=grad_L_s)\n",
    "\n",
    "grad_L_W1 = net.W1.weight.grad\n",
    "grad_L_b1 = net.W1.bias.grad\n",
    "\n",
    "print(\"Gradient of L w.r.t for W1 is:\", grad_L_W1)\n",
    "print(\"Gradient of L w.r.t for b1 is:\", grad_L_b1)\n",
    "\n",
    "display_num_param(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3485d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
